{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Import"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["from yasai_funcs import yasai\n","import torchvision\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader\n","import os\n","import pandas as pd\n","from torchvision import transforms\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from tqdm import tqdm\n","from torch import optim\n","from PIL import Image\n","import torch.nn.functional as F\n","import cv2\n","# from sklearn.model_selection import train_test_split\n","\n","%matplotlib inline"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["# ### for_multi_GPU\n","# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1\"\n","# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n","\n","# print(torch.cuda.device_count())\n","# print(torch.cuda.is_available())"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Root"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["ROOT_PATH = '/home/yasaisen/Desktop/09_research/09_research_main/lab_12'"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["DATA_PATH = '/home/yasaisen/Desktop/09_research/09_research_main/lab_03'\n","\n","dataset_folder = 'dataset_C_v_2.9.3'\n","\n","train_for_base_img_path = os.path.join(DATA_PATH, dataset_folder, 'train_for_base_imgs_rgb')\n","train_for_step_img_path = os.path.join(DATA_PATH, dataset_folder, 'train_for_step_imgs_rgb')\n","\n","valid_img_path = os.path.join(DATA_PATH, dataset_folder, 'valid_imgs_rgb')\n","test_img_path = os.path.join(DATA_PATH, dataset_folder, 'test_imgs_rgb')"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Aug"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["img_size = 224\n","train_bsz = 64\n","device = 'cuda'\n","epochs = 30\n","valid_bsz = 8\n","test_bsz = 8\n","CLASSES = ['NORMAL', 'RLN', 'RSLN']"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Dataset"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["def get_df(img_paths):\n","    images, labels = [], []\n","\n","    i = 0\n","    for img_path in img_paths:\n","        for get_img_name in os.listdir(img_path):\n","            images += [os.path.join(img_path, get_img_name)]\n","            labels += [get_img_name.split('_')[0]]\n","            \n","            i = i+1\n","\n","    PathDF = pd.DataFrame({'images': images, 'labels': labels})\n","    print(i)\n","    PathDF.head()\n","    return PathDF"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["9000\n","1954\n"]}],"source":["train_df = get_df([train_for_base_img_path, train_for_step_img_path])\n","test_df = get_df([valid_img_path, test_img_path])"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"data":{"text/plain":["labels\n","NORMAL    3000\n","RLN       3000\n","RSLN      3000\n","dtype: int64"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["train_df = train_df.sample(frac=1).reset_index(drop=True)\n","train_df.groupby('labels').agg('size')"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["transform = transforms.Compose([\n","            transforms.ToTensor()\n","            ])"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["class mod_Dataset(Dataset):\n","    def __init__(self, path_df, model, transform=None):\n","        self.path_df = path_df\n","        self.transform = transform\n","        self.model = model\n","\n","    def __len__(self):\n","        return self.path_df.shape[0]\n","    \n","    def __getitem__(self, idx):\n","        if self.transform is not None:\n","            trans_Resize = transforms.Resize(224)\n","            trans_ToTensor = transforms.ToTensor()\n","\n","            images = trans_Resize(Image.open(self.path_df.iloc[idx]['images']).convert('RGB'))\n","            images = trans_ToTensor(images)\n","\n","            images = yasai.bounding_crop(images, self.model)\n","            images = images.astype(np.uint8)\n","            images = cv2.cvtColor(images, cv2.COLOR_BGR2RGB)\n","            images = Image.fromarray(images)\n","            images = self.transform(images)\n","\n","            if self.path_df.iloc[idx]['labels'] == CLASSES[0]:\n","                lables = torch.tensor([1, 0, 0], dtype=torch.float32)\n","            if self.path_df.iloc[idx]['labels'] == CLASSES[1]:\n","                lables = torch.tensor([0, 1, 0], dtype=torch.float32)\n","            if self.path_df.iloc[idx]['labels'] == CLASSES[2]:\n","                lables = torch.tensor([0, 0, 1], dtype=torch.float32)\n","\n","        return images, lables"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Successfully loaded from ./../lab_10/model_bast_ima_2305151053.pt\n"]}],"source":["trained_unet_model = yasai.model_load_v1('./../lab_10/model_bast_ima_2305151053.pt').cuda()"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["train_data = mod_Dataset(train_df, trained_unet_model, transform)\n","test_data  = mod_Dataset(test_df, trained_unet_model, transform)\n","\n","train_loader = DataLoader(train_data, batch_size=train_bsz, shuffle=True , num_workers=0, pin_memory=True, drop_last=True)\n","test_loader  = DataLoader(test_data , batch_size=test_bsz , shuffle=False, num_workers=0)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Model"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["class resnet34(nn.Module):\n","    def __init__(self, num_classes):\n","        super().__init__()\n","        self.base_model = torchvision.models.resnet34()\n","        self.dropout = nn.Dropout(p=0.5)\n","        self.fc1 = nn.Linear(1000, num_classes)\n","\n","    def forward(self, input):\n","        output = self.base_model(input)\n","        output = self.dropout(output)\n","        output = self.fc1(output)\n","        output = torch.softmax(output, dim=1)\n","        return output"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([4, 3, 224, 224])\n","torch.Size([4, 3])\n"]},{"name":"stderr","output_type":"stream","text":["/home/yasaisen/.local/lib/python3.8/site-packages/segmentation_models_pytorch/base/modules.py:116: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  return self.activation(x)\n"]},{"name":"stdout","output_type":"stream","text":["torch.Size([64, 3, 224, 224])\n","torch.Size([64, 3])\n"]}],"source":["model = resnet34(len(CLASSES)).to(device)\n","# print(model)\n","t = torch.randn((4, 3, 224, 224)).to(device)\n","print(t.shape)\n","get = model(t)\n","print(get.shape)\n","\n","for x, y in train_loader:\n","    print(x.shape)\n","    print(y.shape)\n","    break"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Train"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["def check_accuracy(loader, model, device):\n","    num_correct = 0\n","    num_samples = 0\n","    model.eval()\n","\n","    with torch.no_grad():\n","        for x, y in loader:\n","            x = x.to(device)\n","            y = y.to(device)\n","\n","            scores = model(x)\n","            _, predictions = scores.max(1)\n","            _, y = y.max(1)\n","            num_correct += (predictions == y).sum()\n","            num_samples += predictions.size(0)\n","\n","    model.train()\n","    return (num_correct/num_samples).item()\n","\n","def train(epochs, model):\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    model = model.to(device)\n","    criterion = nn.CrossEntropyLoss()\n","    optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n","\n","\n","    for epoch in range(epochs):\n","        model.train()\n","        losses = []\n","\n","        pbar = tqdm(train_loader, total=len(train_loader), position=0, leave=True, desc=f\"Epoch {epoch}\")\n","        for data, targets in pbar:\n","            data = data.to(device)\n","            targets = targets.to(device)\n","\n","            # forward\n","            scores = model(data)\n","            # print(scores)\n","            loss = criterion(scores, targets)\n","            losses.append(loss.item())\n","            # backward\n","            optimizer.zero_grad()\n","            loss.backward()\n","\n","            optimizer.step()\n","        \n","        avg_loss = sum(losses) / len(losses)\n","        acc = check_accuracy(test_loader, model, device)\n","        print(f\"Loss:{avg_loss:.8f}\\tAccuracy:{acc:.8f}\")\n","\n","    return model"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Epoch 0:   6%|â–Œ         | 8/140 [00:52<14:24,  6.55s/it]"]}],"source":["trained_resnet34_model = train(5, model)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["yasai.model_save_v1(trained_resnet34_model, 'resnet34_trainsteprgb_2305300859_')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# trained_resnet34_model = yasai.model_load_v1('/home/yasaisen/Desktop/09_research/09_research_main/lab_11/model_resnet34_trainsteprgb_2305290849_2305291051.pt')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["_ = yasai.confusion_matrix(test_data, trained_resnet34_model, CLASSES)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["_ = yasai.confusion_matrix(train_data, trained_resnet34_model, CLASSES)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["t = torch.randn((1, 3, 224, 224)).to(device)\n","print(t.shape)\n","get = trained_resnet34_model(t)\n","print(get)"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"provenance":[]},"gpuClass":"standard","interpreter":{"hash":"a077222d77dfe082b8f1dd562ad70e458ac2ab76993a0b248ab0476e32e9e8dd"},"kernelspec":{"display_name":"Python 3.9.7 ('base')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.16"},"vscode":{"interpreter":{"hash":"369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"}}},"nbformat":4,"nbformat_minor":0}
